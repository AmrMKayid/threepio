{"code": "torch.hub.list(github, force_reload=False)[source]\u00b6", "function_name": "list", "args": ["github"], "kwargs": [[" force_reload", "False"]]}
{"code": "torch.hub.help(github, model, force_reload=False)[source]\u00b6", "function_name": "help", "args": ["github", " model"], "kwargs": [[" force_reload", "False"]]}
{"code": "torch.hub.load(github, model, *args, **kwargs)[source]\u00b6", "function_name": "load", "args": ["github", " model", " *args", " **kwargs"], "kwargs": []}
{"code": "torch.hub.download_url_to_file(url, dst, hash_prefix=None, progress=True)[source]\u00b6", "function_name": "download_url_to_file", "args": ["url", " dst"], "kwargs": [[" hash_prefix", "None"], [" progress", "True"]]}
{"code": "torch.hub.load_state_dict_from_url(url, model_dir=None, map_location=None, progress=True, check_hash=False)[source]\u00b6", "function_name": "load_state_dict_from_url", "args": ["url"], "kwargs": [[" model_dir", "None"], [" map_location", "None"], [" progress", "True"], [" check_hash", "False"]]}
{"code": "torch.hub.set_dir(d)[source]\u00b6", "function_name": "set_dir", "args": ["d"], "kwargs": []}
{"code": "torch.cuda.current_blas_handle()[source]\u00b6", "function_name": "current_blas_handle", "args": [""], "kwargs": []}
{"code": "torch.cuda.current_device()[source]\u00b6", "function_name": "current_device", "args": [""], "kwargs": []}
{"code": "torch.cuda.current_stream(device=None)[source]\u00b6", "function_name": "current_stream", "args": [], "kwargs": [["device", "None"]]}
{"code": "torch.cuda.default_stream(device=None)[source]\u00b6", "function_name": "default_stream", "args": [], "kwargs": [["device", "None"]]}
{"code": "torch.cuda.device_count()[source]\u00b6", "function_name": "device_count", "args": [""], "kwargs": []}
{"code": "torch.cuda.get_device_capability(device=None)[source]\u00b6", "function_name": "get_device_capability", "args": [], "kwargs": [["device", "None"]]}
{"code": "torch.distributions.kl.kl_divergence(p, q)[source]\u00b6", "function_name": "kl_divergence", "args": ["p", " q"], "kwargs": []}
{"code": "torch.cuda.get_device_name(device=None)[source]\u00b6", "function_name": "get_device_name", "args": [], "kwargs": [["device", "None"]]}
{"code": "torch.cuda.init()[source]\u00b6", "function_name": "init", "args": [""], "kwargs": []}
{"code": "torch.cuda.ipc_collect()[source]\u00b6", "function_name": "ipc_collect", "args": [""], "kwargs": []}
{"code": "torch.cuda.is_available()[source]\u00b6", "function_name": "is_available", "args": [""], "kwargs": []}
{"code": "torch.cuda.is_initialized()[source]\u00b6", "function_name": "is_initialized", "args": [""], "kwargs": []}
{"code": "torch.cuda.set_device(device)[source]\u00b6", "function_name": "set_device", "args": ["device"], "kwargs": []}
{"code": "torch.distributions.kl.register_kl(type_p, type_q)[source]\u00b6", "function_name": "register_kl", "args": ["type_p", " type_q"], "kwargs": []}
{"code": "torch.cuda.stream(stream)[source]\u00b6", "function_name": "stream", "args": ["stream"], "kwargs": []}
{"code": "torch.cuda.synchronize(device=None)[source]\u00b6", "function_name": "synchronize", "args": [], "kwargs": [["device", "None"]]}
{"code": "bernoulli_(p=0.5, *, generator=None) \u2192 Tensor", "function_name": "bernoulli_", "args": [" *"], "kwargs": [["p", "0.5"], [" generator", "None"]]}
{"code": "torch.jit.script(obj)[source]\u00b6", "function_name": "script", "args": ["obj"], "kwargs": []}
{"code": "torch.autograd.backward(tensors, grad_tensors=None, retain_graph=None, create_graph=False, grad_variables=None)[source]\u00b6", "function_name": "backward", "args": ["tensors"], "kwargs": [[" grad_tensors", "None"], [" retain_graph", "None"], [" create_graph", "False"], [" grad_variables", "None"]]}
{"code": "bernoulli_(p_tensor, *, generator=None) \u2192 Tensor", "function_name": "bernoulli_", "args": ["p_tensor", " *"], "kwargs": [[" generator", "None"]]}
{"code": "torch.autograd.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False, only_inputs=True, allow_unused=False)[source]\u00b6", "function_name": "grad", "args": ["outputs", " inputs"], "kwargs": [[" grad_outputs", "None"], [" retain_graph", "None"], [" create_graph", "False"], [" only_inputs", "True"], [" allow_unused", "False"]]}
{"code": "torch.onnx.export(model, args, f, export_params=True, verbose=False, training=False, input_names=None, output_names=None, aten=False, export_raw_ir=False, operator_export_type=None, opset_version=None, _retain_param_name=True, do_constant_folding=False, example_outputs=None, strip_doc_string=True, dynamic_axes=None, keep_initializers_as_inputs=None)[source]\u00b6", "function_name": "export", "args": ["model", " args", " f"], "kwargs": [[" export_params", "True"], [" verbose", "False"], [" training", "False"], [" input_names", "None"], [" output_names", "None"], [" aten", "False"], [" export_raw_ir", "False"], [" operator_export_type", "None"], [" opset_version", "None"], [" _retain_param_name", "True"], [" do_constant_folding", "False"], [" example_outputs", "None"], [" strip_doc_string", "True"], [" dynamic_axes", "None"], [" keep_initializers_as_inputs", "None"]]}
{"code": "torch.is_tensor(obj)[source]\u00b6", "function_name": "is_tensor", "args": ["obj"], "kwargs": []}
{"code": "to(dtype, non_blocking=False, copy=False) \u2192 Tensor", "function_name": "to", "args": ["dtype"], "kwargs": [[" non_blocking", "False"], [" copy", "False"]]}
{"code": "to(device=None, dtype=None, non_blocking=False, copy=False) \u2192 Tensor", "function_name": "to", "args": [], "kwargs": [["device", "None"], [" dtype", "None"], [" non_blocking", "False"], [" copy", "False"]]}
{"code": "to(other, non_blocking=False, copy=False) \u2192 Tensor", "function_name": "to", "args": ["other"], "kwargs": [[" non_blocking", "False"], [" copy", "False"]]}
{"code": "all() \u2192 bool", "function_name": "all", "args": [""], "kwargs": []}
{"code": "all(dim, keepdim=False, out=None) \u2192 Tensor", "function_name": "all", "args": ["dim"], "kwargs": [[" keepdim", "False"], [" out", "None"]]}
{"code": "any() \u2192 bool", "function_name": "any", "args": [""], "kwargs": []}
{"code": "any(dim, keepdim=False, out=None) \u2192 Tensor", "function_name": "any", "args": ["dim"], "kwargs": [[" keepdim", "False"], [" out", "None"]]}
{"code": "torch.onnx.register_custom_op_symbolic(symbolic_name, symbolic_fn, opset_version)[source]\u00b6", "function_name": "register_custom_op_symbolic", "args": ["symbolic_name", " symbolic_fn", " opset_version"], "kwargs": []}
{"code": "torch.onnx.operators.shape_as_tensor(x)[source]\u00b6", "function_name": "shape_as_tensor", "args": ["x"], "kwargs": []}
{"code": "torch.onnx.set_training(model, mode)[source]\u00b6", "function_name": "set_training", "args": ["model", " mode"], "kwargs": []}
{"code": "torch.onnx.is_in_onnx_export()[source]\u00b6", "function_name": "is_in_onnx_export", "args": [""], "kwargs": []}
{"code": "torch.is_storage(obj)[source]\u00b6", "function_name": "is_storage", "args": ["obj"], "kwargs": []}
{"code": "torch.is_floating_point(input) -&gt; (bool)\u00b6", "function_name": "is_floating_point", "args": ["input"], "kwargs": []}
{"code": "torch.set_default_dtype(d)[source]\u00b6", "function_name": "set_default_dtype", "args": ["d"], "kwargs": []}
{"code": "torch.get_default_dtype() \u2192 torch.dtype\u00b6", "function_name": "get_default_dtype", "args": [""], "kwargs": []}
{"code": "torch.set_default_tensor_type(t)[source]\u00b6", "function_name": "set_default_tensor_type", "args": ["t"], "kwargs": []}
{"code": "torch.numel(input) \u2192 int\u00b6", "function_name": "numel", "args": ["input"], "kwargs": []}
{"code": "torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)[source]\u00b6", "function_name": "set_printoptions", "args": [], "kwargs": [["precision", "None"], [" threshold", "None"], [" edgeitems", "None"], [" linewidth", "None"], [" profile", "None"], [" sci_mode", "None"]]}
{"code": "torch.set_flush_denormal(mode) \u2192 bool\u00b6", "function_name": "set_flush_denormal", "args": ["mode"], "kwargs": []}
{"code": "torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) \u2192 Tensor\u00b6", "function_name": "tensor", "args": ["data"], "kwargs": [[" dtype", "None"], [" device", "None"], [" requires_grad", "False"], [" pin_memory", "False"]]}
{"code": "torch.sparse_coo_tensor(indices, values, size=None, dtype=None, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "sparse_coo_tensor", "args": ["indices", " values"], "kwargs": [[" size", "None"], [" dtype", "None"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.as_tensor(data, dtype=None, device=None) \u2192 Tensor\u00b6", "function_name": "as_tensor", "args": ["data"], "kwargs": [[" dtype", "None"], [" device", "None"]]}
{"code": "torch.as_strided(input, size, stride, storage_offset=0) \u2192 Tensor\u00b6", "function_name": "as_strided", "args": ["input", " size", " stride"], "kwargs": [[" storage_offset", "0"]]}
{"code": "torch.from_numpy(ndarray) \u2192 Tensor\u00b6", "function_name": "from_numpy", "args": ["ndarray"], "kwargs": []}
{"code": "torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "zeros", "args": ["*size"], "kwargs": [[" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "zeros_like", "args": ["input"], "kwargs": [[" dtype", "None"], [" layout", "None"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "ones", "args": ["*size"], "kwargs": [[" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "ones_like", "args": ["input"], "kwargs": [[" dtype", "None"], [" layout", "None"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "arange", "args": [" end"], "kwargs": [["start", "0"], [" step", "1"], [" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.range(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "range", "args": [" end"], "kwargs": [["start", "0"], [" step", "1"], [" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "linspace", "args": ["start", " end"], "kwargs": [[" steps", "100"], [" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "logspace", "args": ["start", " end"], "kwargs": [[" steps", "100"], [" base", "10.0"], [" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "eye", "args": ["n"], "kwargs": [[" m", "None"], [" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.empty(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) \u2192 Tensor\u00b6", "function_name": "empty", "args": ["*size"], "kwargs": [[" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"], [" pin_memory", "False"]]}
{"code": "torch.empty_like(input, dtype=None, layout=None, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "empty_like", "args": ["input"], "kwargs": [[" dtype", "None"], [" layout", "None"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.empty_strided(size, stride, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False) \u2192 Tensor\u00b6", "function_name": "empty_strided", "args": ["size", " stride"], "kwargs": [[" dtype", "None"], [" layout", "None"], [" device", "None"], [" requires_grad", "False"], [" pin_memory", "False"]]}
{"code": "torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "full", "args": ["size", " fill_value"], "kwargs": [[" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.sparse.addmm(mat, mat1, mat2, beta=1, alpha=1)[source]\u00b6", "function_name": "addmm", "args": ["mat", " mat1", " mat2"], "kwargs": [[" beta", "1"], [" alpha", "1"]]}
{"code": "torch.full_like(input, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "full_like", "args": ["input", " fill_value"], "kwargs": [[" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.quantize_per_tensor(input, scale, zero_point, dtype) \u2192 Tensor\u00b6", "function_name": "quantize_per_tensor", "args": ["input", " scale", " zero_point", " dtype"], "kwargs": []}
{"code": "torch.quantize_per_channel(input, scales, zero_points, axis, dtype) \u2192 Tensor\u00b6", "function_name": "quantize_per_channel", "args": ["input", " scales", " zero_points", " axis", " dtype"], "kwargs": []}
{"code": "torch.cat(tensors, dim=0, out=None) \u2192 Tensor\u00b6", "function_name": "cat", "args": ["tensors"], "kwargs": [[" dim", "0"], [" out", "None"]]}
{"code": "torch.chunk(input, chunks, dim=0) \u2192 List of Tensors\u00b6", "function_name": "chunk", "args": ["input", " chunks"], "kwargs": [[" dim", "0"]]}
{"code": "torch.gather(input, dim, index, out=None, sparse_grad=False) \u2192 Tensor\u00b6", "function_name": "gather", "args": ["input", " dim", " index"], "kwargs": [[" out", "None"], [" sparse_grad", "False"]]}
{"code": "torch.index_select(input, dim, index, out=None) \u2192 Tensor\u00b6", "function_name": "index_select", "args": ["input", " dim", " index"], "kwargs": [[" out", "None"]]}
{"code": "torch.masked_select(input, mask, out=None) \u2192 Tensor\u00b6", "function_name": "masked_select", "args": ["input", " mask"], "kwargs": [[" out", "None"]]}
{"code": "torch.narrow(input, dim, start, length) \u2192 Tensor\u00b6", "function_name": "narrow", "args": ["input", " dim", " start", " length"], "kwargs": []}
{"code": "torch.nonzero(input, *, out=None, as_tuple=False) \u2192 LongTensor or tuple of LongTensors\u00b6", "function_name": "nonzero", "args": ["input", " *"], "kwargs": [[" out", "None"], [" as_tuple", "False"]]}
{"code": "torch.reshape(input, shape) \u2192 Tensor\u00b6", "function_name": "reshape", "args": ["input", " shape"], "kwargs": []}
{"code": "torch.split(tensor, split_size_or_sections, dim=0)[source]\u00b6", "function_name": "split", "args": ["tensor", " split_size_or_sections"], "kwargs": [[" dim", "0"]]}
{"code": "torch.squeeze(input, dim=None, out=None) \u2192 Tensor\u00b6", "function_name": "squeeze", "args": ["input"], "kwargs": [[" dim", "None"], [" out", "None"]]}
{"code": "torch.stack(tensors, dim=0, out=None) \u2192 Tensor\u00b6", "function_name": "stack", "args": ["tensors"], "kwargs": [[" dim", "0"], [" out", "None"]]}
{"code": "torch.t(input) \u2192 Tensor\u00b6", "function_name": "t", "args": ["input"], "kwargs": []}
{"code": "torch.take(input, index) \u2192 Tensor\u00b6", "function_name": "take", "args": ["input", " index"], "kwargs": []}
{"code": "torch.transpose(input, dim0, dim1) \u2192 Tensor\u00b6", "function_name": "transpose", "args": ["input", " dim0", " dim1"], "kwargs": []}
{"code": "torch.sparse.mm(mat1, mat2)[source]\u00b6", "function_name": "mm", "args": ["mat1", " mat2"], "kwargs": []}
{"code": "torch.sparse.sum(input, dim=None, dtype=None)[source]\u00b6", "function_name": "sum", "args": ["input"], "kwargs": [[" dim", "None"], [" dtype", "None"]]}
{"code": "to(device=None, dtype=None, non_blocking=False)[source]", "function_name": "to", "args": [], "kwargs": [["device", "None"], [" dtype", "None"], [" non_blocking", "False"]]}
{"code": "torch.unbind(input, dim=0) \u2192 seq\u00b6", "function_name": "unbind", "args": ["input"], "kwargs": [[" dim", "0"]]}
{"code": "torch.unsqueeze(input, dim, out=None) \u2192 Tensor\u00b6", "function_name": "unsqueeze", "args": ["input", " dim"], "kwargs": [[" out", "None"]]}
{"code": "torch.where()\u00b6", "function_name": "where", "args": [""], "kwargs": []}
{"code": "torch.where(condition, x, y) \u2192 Tensor", "function_name": "where", "args": ["condition", " x", " y"], "kwargs": []}
{"code": "torch.where(condition) \u2192 tuple of LongTensor", "function_name": "where", "args": ["condition"], "kwargs": []}
{"code": "torch.seed()[source]\u00b6", "function_name": "seed", "args": [""], "kwargs": []}
{"code": "torch.manual_seed(seed)[source]\u00b6", "function_name": "manual_seed", "args": ["seed"], "kwargs": []}
{"code": "torch.initial_seed()[source]\u00b6", "function_name": "initial_seed", "args": [""], "kwargs": []}
{"code": "torch.get_rng_state()[source]\u00b6", "function_name": "get_rng_state", "args": [""], "kwargs": []}
{"code": "torch.set_rng_state(new_state)[source]\u00b6", "function_name": "set_rng_state", "args": ["new_state"], "kwargs": []}
{"code": "torch.bernoulli(input, *, generator=None, out=None) \u2192 Tensor\u00b6", "function_name": "bernoulli", "args": ["input", " *"], "kwargs": [[" generator", "None"], [" out", "None"]]}
{"code": "torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None) \u2192 LongTensor\u00b6", "function_name": "multinomial", "args": ["input", " num_samples", " *"], "kwargs": [[" replacement", "False"], [" generator", "None"], [" out", "None"]]}
{"code": "torch.normal()\u00b6", "function_name": "normal", "args": [""], "kwargs": []}
{"code": "torch.normal(mean, std, *, generator=None, out=None) \u2192 Tensor", "function_name": "normal", "args": ["mean", " std", " *"], "kwargs": [[" generator", "None"], [" out", "None"]]}
{"code": "torch.normal(mean=0.0, std, out=None) \u2192 Tensor", "function_name": "normal", "args": [" std"], "kwargs": [["mean", "0.0"], [" out", "None"]]}
{"code": "torch.normal(mean, std=1.0, out=None) \u2192 Tensor", "function_name": "normal", "args": ["mean"], "kwargs": [[" std", "1.0"], [" out", "None"]]}
{"code": "torch.normal(mean, std, size, *, out=None) \u2192 Tensor", "function_name": "normal", "args": ["mean", " std", " size", " *"], "kwargs": [[" out", "None"]]}
{"code": "torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "rand", "args": ["*size"], "kwargs": [[" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.rand_like(input, dtype=None, layout=None, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "rand_like", "args": ["input"], "kwargs": [[" dtype", "None"], [" layout", "None"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "randint", "args": [" high", " size", " *"], "kwargs": [["low", "0"], [" generator", "None"], [" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "to(dtype, non_blocking=False)[source]", "function_name": "to", "args": ["dtype"], "kwargs": [[" non_blocking", "False"]]}
{"code": "to(tensor, non_blocking=False)[source]", "function_name": "to", "args": ["tensor"], "kwargs": [[" non_blocking", "False"]]}
{"code": "torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=2)[source]\u00b6", "function_name": "clip_grad_norm_", "args": ["parameters", " max_norm"], "kwargs": [[" norm_type", "2"]]}
{"code": "torch.nn.utils.clip_grad_value_(parameters, clip_value)[source]\u00b6", "function_name": "clip_grad_value_", "args": ["parameters", " clip_value"], "kwargs": []}
{"code": "torch.nn.utils.parameters_to_vector(parameters)[source]\u00b6", "function_name": "parameters_to_vector", "args": ["parameters"], "kwargs": []}
{"code": "torch.randint_like(input, low=0, high, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "randint_like", "args": ["input", " high"], "kwargs": [[" low", "0"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "randn", "args": ["*size"], "kwargs": [[" out", "None"], [" dtype", "None"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.randn_like(input, dtype=None, layout=None, device=None, requires_grad=False) \u2192 Tensor\u00b6", "function_name": "randn_like", "args": ["input"], "kwargs": [[" dtype", "None"], [" layout", "None"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) \u2192 LongTensor\u00b6", "function_name": "randperm", "args": ["n"], "kwargs": [[" out", "None"], [" dtype", "torch.int64"], [" layout", "torch.strided"], [" device", "None"], [" requires_grad", "False"]]}
{"code": "torch.nn.utils.vector_to_parameters(vec, parameters)[source]\u00b6", "function_name": "vector_to_parameters", "args": ["vec", " parameters"], "kwargs": []}
{"code": "torch.nn.utils.prune.identity(module, name)[source]\u00b6", "function_name": "identity", "args": ["module", " name"], "kwargs": []}
{"code": "torch.nn.utils.prune.random_unstructured(module, name, amount)[source]\u00b6", "function_name": "random_unstructured", "args": ["module", " name", " amount"], "kwargs": []}
{"code": "torch.nn.utils.prune.l1_unstructured(module, name, amount)[source]\u00b6", "function_name": "l1_unstructured", "args": ["module", " name", " amount"], "kwargs": []}
{"code": "torch.nn.utils.prune.random_structured(module, name, amount, dim)[source]\u00b6", "function_name": "random_structured", "args": ["module", " name", " amount", " dim"], "kwargs": []}
{"code": "torch.nn.utils.prune.ln_structured(module, name, amount, n, dim)[source]\u00b6", "function_name": "ln_structured", "args": ["module", " name", " amount", " n", " dim"], "kwargs": []}
{"code": "torch.nn.utils.prune.global_unstructured(parameters, pruning_method, **kwargs)[source]\u00b6", "function_name": "global_unstructured", "args": ["parameters", " pruning_method", " **kwargs"], "kwargs": []}
{"code": "torch.nn.utils.prune.custom_from_mask(module, name, mask)[source]\u00b6", "function_name": "custom_from_mask", "args": ["module", " name", " mask"], "kwargs": []}
{"code": "torch.nn.utils.prune.remove(module, name)[source]\u00b6", "function_name": "remove", "args": ["module", " name"], "kwargs": []}
{"code": "torch.nn.utils.prune.is_pruned(module)[source]\u00b6", "function_name": "is_pruned", "args": ["module"], "kwargs": []}
{"code": "torch.utils.checkpoint.checkpoint(function, *args, **kwargs)[source]\u00b6", "function_name": "checkpoint", "args": ["function", " *args", " **kwargs"], "kwargs": []}
{"code": "torch.utils.data.get_worker_info()[source]\u00b6", "function_name": "get_worker_info", "args": [""], "kwargs": []}
{"code": "torch.utils.checkpoint.checkpoint_sequential(functions, segments, *inputs, **kwargs)[source]\u00b6", "function_name": "checkpoint_sequential", "args": ["functions", " segments", " *inputs", " **kwargs"], "kwargs": []}
{"code": "torch.utils.data.random_split(dataset, lengths)[source]\u00b6", "function_name": "random_split", "args": ["dataset", " lengths"], "kwargs": []}
{"code": "torch.utils.model_zoo.load_url(url, model_dir=None, map_location=None, progress=True, check_hash=False)\u00b6", "function_name": "load_url", "args": ["url"], "kwargs": [[" model_dir", "None"], [" map_location", "None"], [" progress", "True"], [" check_hash", "False"]]}
{"code": "torch.utils.dlpack.from_dlpack(dlpack) \u2192 Tensor\u00b6", "function_name": "from_dlpack", "args": ["dlpack"], "kwargs": []}
{"code": "torch.utils.dlpack.to_dlpack(tensor) \u2192 PyCapsule\u00b6", "function_name": "to_dlpack", "args": ["tensor"], "kwargs": []}
